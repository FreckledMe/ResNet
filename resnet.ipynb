{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,BatchNormalization,ReLU,Add,AveragePooling2D,Dense,Flatten,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7328 files belonging to 15 classes.\n",
      "Found 1841 files belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'dataset/train',\n",
    "    seed=123,\n",
    "    batch_size=32,\n",
    "    image_size=(224,224))\n",
    "\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'dataset/test/',\n",
    "    seed=123,\n",
    "    image_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(tf.keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet34, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=7, strides=2, padding=\"same\")\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu1 = tf.keras.layers.Activation(\"relu\")\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding=\"same\")\n",
    "        \n",
    "        self.block1 = self.build_block(64, 3, first_block=True)\n",
    "        self.block2 = self.build_block(128, 4)\n",
    "        self.block3 = self.build_block(256, 6)\n",
    "        self.block4 = self.build_block(512, 3)\n",
    "        \n",
    "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc = tf.keras.layers.Dense(units=num_classes, activation=\"softmax\")\n",
    "        \n",
    "    def build_block(self, filters, num_blocks, first_block=False):\n",
    "        strides = 1\n",
    "        if not first_block:\n",
    "            strides = 2\n",
    "            \n",
    "        layers = []\n",
    "        layers.append(tf.keras.layers.Conv2D(filters=filters, kernel_size=1, strides=strides, padding=\"same\"))\n",
    "        layers.append(tf.keras.layers.BatchNormalization())\n",
    "        layers.append(tf.keras.layers.Activation(\"relu\"))\n",
    "        \n",
    "        for _ in range(num_blocks):\n",
    "            layers.append(tf.keras.layers.Conv2D(filters=filters, kernel_size=3, strides=1, padding=\"same\"))\n",
    "            layers.append(tf.keras.layers.BatchNormalization())\n",
    "            layers.append(tf.keras.layers.Activation(\"relu\"))\n",
    "            \n",
    "        return tf.keras.Sequential(layers)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=15\n",
    "model = ResNet34(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(32,224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justf\\miniconda3\\envs\\gpu\\lib\\site-packages\\keras\\backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.6358394622802734, Accuracy: 14.287664413452148, Test Loss: 9.059215545654297, Test Accuracy: 8.039109230041504\n",
      "Epoch 2, Loss: 2.4731245040893555, Accuracy: 19.978164672851562, Test Loss: 4.7100419998168945, Test Accuracy: 11.026616096496582\n",
      "Epoch 3, Loss: 2.4356935024261475, Accuracy: 21.233623504638672, Test Loss: 7.826407432556152, Test Accuracy: 13.253666877746582\n",
      "Epoch 4, Loss: 2.396591901779175, Accuracy: 22.502729415893555, Test Loss: 3.019244432449341, Test Accuracy: 17.110265731811523\n",
      "Epoch 5, Loss: 2.3565561771392822, Accuracy: 23.21233558654785, Test Loss: 2.9512381553649902, Test Accuracy: 21.944595336914062\n",
      "Epoch 6, Loss: 2.344533920288086, Accuracy: 23.66266441345215, Test Loss: 2.686108112335205, Test Accuracy: 21.292776107788086\n",
      "Epoch 7, Loss: 2.3119351863861084, Accuracy: 24.945415496826172, Test Loss: 2.7766499519348145, Test Accuracy: 18.196632385253906\n",
      "Epoch 8, Loss: 2.2485556602478027, Accuracy: 27.442684173583984, Test Loss: 2.458317756652832, Test Accuracy: 22.70505142211914\n",
      "Epoch 9, Loss: 2.2137179374694824, Accuracy: 28.07041358947754, Test Loss: 3.2818000316619873, Test Accuracy: 18.305269241333008\n",
      "Epoch 10, Loss: 2.1519994735717773, Accuracy: 30.28111457824707, Test Loss: 2.6345224380493164, Test Accuracy: 20.423683166503906\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "with tf.device('/device:GPU:0'):\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        test_loss.reset_states()\n",
    "        test_accuracy.reset_states()\n",
    "\n",
    "        for images, labels in train_ds:\n",
    "            train_step(images, labels)\n",
    "        for test_images, test_labels in test_ds:\n",
    "            test_step(test_images, test_labels)\n",
    "        print(\n",
    "            f'Epoch {epoch + 1}, '\n",
    "            f'Loss: {train_loss.result()}, '\n",
    "            f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "            f'Test Loss: {test_loss.result()}, '\n",
    "            f'Test Accuracy: {test_accuracy.result() * 100}')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
